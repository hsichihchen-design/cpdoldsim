"""
Step 5: å¤šå¤©é€£çºŒé‹ä½œé©—è­‰
é©—è­‰ç³»çµ±åœ¨å¤šå¤©é€£çºŒé‹ä½œä¸‹çš„ç©©å®šæ€§ã€è¶¨å‹¢å’Œç´¯ç©æ•ˆæ‡‰
"""

import pandas as pd
import numpy as np
import sys
import os
from datetime import datetime, date, time, timedelta
from collections import defaultdict

# åŠ å…¥çˆ¶ç›®éŒ„ä»¥ä¾¿ import
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data_manager import DataManager

def validate_multi_day_operations(start_date="2024-06-10", end_date="2024-06-16"):
    """é©—è­‰å¤šå¤©é€£çºŒé‹ä½œ"""
    print(f"ğŸ“Š Step 5: é©—è­‰å¤šå¤©é€£çºŒé‹ä½œ...")
    print(f"  é–‹å§‹æ—¥æœŸ: {start_date}")
    print(f"  çµæŸæ—¥æœŸ: {end_date}")
    
    # è¨ˆç®—ç¸½å¤©æ•¸
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    total_days = (end_dt - start_dt).days + 1
    
    print(f"  ç¸½å¤©æ•¸: {total_days} å¤©")
    
    # åˆå§‹åŒ–ç³»çµ±
    data_manager = DataManager()
    
    # è¼‰å…¥è³‡æ–™
    print("\nğŸ“š è¼‰å…¥å¤šå¤©è³‡æ–™...")
    master_data = data_manager.load_master_data()
    transaction_data = data_manager.load_transaction_data(
        start_date=start_date,
        end_date=end_date,
        filter_valid_items=True
    )
    
    orders_df = transaction_data.get('historical_orders', pd.DataFrame())
    receiving_df = transaction_data.get('historical_receiving', pd.DataFrame())
    
    print(f"  æœŸé–“è¨‚å–®ç¸½æ•¸: {len(orders_df):,} ç­†")
    print(f"  æœŸé–“é€²è²¨ç¸½æ•¸: {len(receiving_df):,} ç­†")
    
    # Step 1: æŒ‰æ—¥æœŸåˆ†æè³‡æ–™åˆ†å¸ƒ
    print(f"\nğŸ“ˆ Step 1: åˆ†æè³‡æ–™åˆ†å¸ƒ...")
    
    # åˆ†æè¨‚å–®æ—¥æœŸåˆ†å¸ƒ
    if len(orders_df) > 0 and 'DATE' in orders_df.columns:
        orders_df['order_date'] = pd.to_datetime(orders_df['DATE']).dt.date
        daily_order_counts = orders_df['order_date'].value_counts().sort_index()
        
        print(f"  æ¯æ—¥è¨‚å–®åˆ†å¸ƒ:")
        for order_date, count in daily_order_counts.items():
            weekday = order_date.strftime('%A')
            print(f"    {order_date} ({weekday}): {count:,} ç­†")
    
    # åˆ†æé€²è²¨æ—¥æœŸåˆ†å¸ƒ
    if len(receiving_df) > 0 and 'DATE' in receiving_df.columns:
        receiving_df['receiving_date'] = pd.to_datetime(receiving_df['DATE']).dt.date
        daily_receiving_counts = receiving_df['receiving_date'].value_counts().sort_index()
        
        print(f"\n  æ¯æ—¥é€²è²¨åˆ†å¸ƒ:")
        for receiving_date, count in daily_receiving_counts.items():
            weekday = receiving_date.strftime('%A')
            print(f"    {receiving_date} ({weekday}): {count:,} ç­†")
    
    # Step 2: åŸ·è¡Œæ¯æ—¥é©—è­‰
    print(f"\nğŸ”„ Step 2: åŸ·è¡Œæ¯æ—¥é©—è­‰...")
    
    daily_results = {}
    cumulative_metrics = {
        'total_orders_processed': 0,
        'total_tasks_assigned': 0,
        'total_tasks_unassigned': 0,
        'total_overtime_hours': 0,
        'total_conflicts': 0,
        'avg_utilization': [],
        'avg_success_rate': []
    }
    
    # è¿½è¹¤é€²è²¨ä»»å‹™çš„ç´¯ç©æƒ…æ³
    receiving_backlog = defaultdict(list)  # æŒ‰æ¨“å±¤è¿½è¹¤ç©å£“
    overdue_receiving = []
    
    current_date = start_dt
    
    while current_date <= end_dt:
        date_str = current_date.strftime('%Y-%m-%d')
        weekday = current_date.strftime('%A')
        
        print(f"\n  è™•ç†æ—¥æœŸ: {date_str} ({weekday})")
        
        # è·³éé€±æœ«ï¼ˆå¦‚æœè³‡æ–™ç®¡ç†å™¨æœ‰æ­¤è¨­å®šï¼‰
        if not data_manager.is_workday(current_date):
            print(f"    è·³éé€±æœ«")
            current_date += timedelta(days=1)
            continue
        
        try:
            # å˜—è©¦åŸ·è¡Œå–®æ—¥é©—è­‰
            daily_result = run_single_day_validation(date_str)
            
            if daily_result:
                daily_results[date_str] = daily_result
                
                # ç´¯ç©æŒ‡æ¨™
                summary = daily_result['daily_summary']
                cumulative_metrics['total_orders_processed'] += summary.get('total_shipping_orders', 0)
                cumulative_metrics['total_tasks_assigned'] += summary.get('total_assigned_tasks', 0)
                cumulative_metrics['total_tasks_unassigned'] += summary.get('total_unassigned_tasks', 0)
                cumulative_metrics['total_overtime_hours'] += summary.get('estimated_overtime_hours', 0)
                cumulative_metrics['total_conflicts'] += summary.get('station_conflicts', 0)
                
                if summary.get('peak_station_utilization') is not None:
                    cumulative_metrics['avg_utilization'].append(summary['peak_station_utilization'])
                
                if summary.get('assignment_success_rate') is not None:
                    cumulative_metrics['avg_success_rate'].append(summary['assignment_success_rate'])
                
                print(f"    âœ… è™•ç†å®Œæˆ")
                print(f"       è¨‚å–®: {summary.get('total_shipping_orders', 0)} ç­†")
                print(f"       åˆ†é…æˆåŠŸç‡: {summary.get('assignment_success_rate', 0):.1f}%")
                print(f"       å³°å€¼åˆ©ç”¨ç‡: {summary.get('peak_station_utilization', 0):.1f}%")
                
                # è¿½è¹¤é€²è²¨ç©å£“æƒ…æ³
                receiving_tasks = summary.get('total_receiving_tasks', 0)
                if receiving_tasks > 0:
                    # ç°¡åŒ–çš„ç©å£“è¿½è¹¤é‚è¼¯
                    unassigned_receiving = daily_result.get('overtime_analysis', {}).get('overtime_by_type', {}).get('receiving', 0)
                    if unassigned_receiving > 0:
                        receiving_backlog[date_str].append(unassigned_receiving)
                
            else:
                print(f"    âš ï¸ è™•ç†å¤±æ•—")
                daily_results[date_str] = None
        
        except Exception as e:
            print(f"    âŒ è™•ç†éŒ¯èª¤: {str(e)}")
            daily_results[date_str] = None
        
        current_date += timedelta(days=1)
    
    # Step 3: è¶¨å‹¢åˆ†æ
    print(f"\nğŸ“Š Step 3: è¶¨å‹¢åˆ†æ...")
    
    # å»ºç«‹è¶¨å‹¢è³‡æ–™
    trend_data = []
    
    for date_str, result in daily_results.items():
        if result:
            summary = result['daily_summary']
            trend_data.append({
                'date': date_str,
                'weekday': datetime.strptime(date_str, '%Y-%m-%d').strftime('%A'),
                'total_orders': summary.get('total_shipping_orders', 0),
                'total_tasks': summary.get('total_assigned_tasks', 0) + summary.get('total_unassigned_tasks', 0),
                'assigned_tasks': summary.get('total_assigned_tasks', 0),
                'success_rate': summary.get('assignment_success_rate', 0),
                'utilization': summary.get('peak_station_utilization', 0),
                'conflicts': summary.get('station_conflicts', 0),
                'overtime_hours': summary.get('estimated_overtime_hours', 0)
            })
    
    if trend_data:
        trend_df = pd.DataFrame(trend_data)
        
        # è¨ˆç®—è¶¨å‹¢çµ±è¨ˆ
        trend_stats = {
            'avg_daily_orders': trend_df['total_orders'].mean(),
            'max_daily_orders': trend_df['total_orders'].max(),
            'min_daily_orders': trend_df['total_orders'].min(),
            'avg_success_rate': trend_df['success_rate'].mean(),
            'avg_utilization': trend_df['utilization'].mean(),
            'total_conflicts': trend_df['conflicts'].sum(),
            'total_overtime': trend_df['overtime_hours'].sum(),
            'trend_stability': trend_df['success_rate'].std(),  # ç©©å®šæ€§æŒ‡æ¨™
        }
        
        print(f"  è¶¨å‹¢çµ±è¨ˆ:")
        print(f"    å¹³å‡æ¯æ—¥è¨‚å–®: {trend_stats['avg_daily_orders']:.0f} ç­†")
        print(f"    æœ€å¤§æ¯æ—¥è¨‚å–®: {trend_stats['max_daily_orders']:.0f} ç­†")
        print(f"    å¹³å‡åˆ†é…æˆåŠŸç‡: {trend_stats['avg_success_rate']:.1f}%")
        print(f"    å¹³å‡åˆ©ç”¨ç‡: {trend_stats['avg_utilization']:.1f}%")
        print(f"    ç¸½è¡çªæ•¸: {trend_stats['total_conflicts']:.0f} å€‹")
        print(f"    ç¸½åŠ ç­æ™‚æ•¸: {trend_stats['total_overtime']:.1f} å°æ™‚")
        print(f"    ç©©å®šæ€§æŒ‡æ¨™: {trend_stats['trend_stability']:.2f} (æ•¸å€¼è¶Šå°è¶Šç©©å®š)")
        
        # é€±å…§æ¨¡å¼åˆ†æ
        weekday_analysis = trend_df.groupby('weekday').agg({
            'total_orders': 'mean',
            'success_rate': 'mean',
            'utilization': 'mean',
            'overtime_hours': 'sum'
        }).round(2)
        
        print(f"\n  é€±å…§æ¨¡å¼åˆ†æ:")
        for weekday, stats in weekday_analysis.iterrows():
            print(f"    {weekday}: è¨‚å–® {stats['total_orders']:.0f}, æˆåŠŸç‡ {stats['success_rate']:.1f}%, åˆ©ç”¨ç‡ {stats['utilization']:.1f}%")
    
    # Step 4: é€²è²¨ç©å£“åˆ†æ
    print(f"\nğŸ“¦ Step 4: é€²è²¨ç©å£“åˆ†æ...")
    
    if receiving_backlog:
        total_backlog_days = len(receiving_backlog)
        avg_daily_backlog = np.mean([sum(tasks) for tasks in receiving_backlog.values()])
        
        print(f"  é€²è²¨ç©å£“æƒ…æ³:")
        print(f"    ç™¼ç”Ÿç©å£“å¤©æ•¸: {total_backlog_days} å¤©")
        print(f"    å¹³å‡æ¯æ—¥ç©å£“: {avg_daily_backlog:.1f} å€‹ä»»å‹™")
        
        # æ¨¡æ“¬é€²è²¨æœŸé™è¿½è¹¤
        simulated_overdue = 0
        for date_str, backlog_tasks in receiving_backlog.items():
            # å‡è¨­ç©å£“ä»»å‹™æœƒç´¯ç©åˆ°ä¸‹ä¸€å¤©
            simulated_overdue += len(backlog_tasks)
        
        print(f"    æ¨¡æ“¬ç´¯ç©é€¾æœŸ: {simulated_overdue} å€‹ä»»å‹™")
    else:
        print(f"  âœ… ç„¡é€²è²¨ç©å£“")
    
    # Step 5: ç³»çµ±ç©©å®šæ€§è©•ä¼°
    print(f"\nğŸ”§ Step 5: ç³»çµ±ç©©å®šæ€§è©•ä¼°...")
    
    stability_metrics = {
        'data_coverage': len([r for r in daily_results.values() if r is not None]) / len(daily_results) * 100,
        'avg_success_rate': np.mean(cumulative_metrics['avg_success_rate']) if cumulative_metrics['avg_success_rate'] else 0,
        'success_rate_stability': np.std(cumulative_metrics['avg_success_rate']) if cumulative_metrics['avg_success_rate'] else 0,
        'avg_utilization': np.mean(cumulative_metrics['avg_utilization']) if cumulative_metrics['avg_utilization'] else 0,
        'utilization_stability': np.std(cumulative_metrics['avg_utilization']) if cumulative_metrics['avg_utilization'] else 0,
        'conflict_frequency': cumulative_metrics['total_conflicts'] / len(daily_results),
        'overtime_frequency': cumulative_metrics['total_overtime_hours'] / len(daily_results)
    }
    
    print(f"  ç©©å®šæ€§æŒ‡æ¨™:")
    print(f"    è³‡æ–™è¦†è“‹ç‡: {stability_metrics['data_coverage']:.1f}%")
    print(f"    å¹³å‡åˆ†é…æˆåŠŸç‡: {stability_metrics['avg_success_rate']:.1f}%")
    print(f"    æˆåŠŸç‡ç©©å®šæ€§: {stability_metrics['success_rate_stability']:.2f}")
    print(f"    å¹³å‡åˆ©ç”¨ç‡: {stability_metrics['avg_utilization']:.1f}%")
    print(f"    åˆ©ç”¨ç‡ç©©å®šæ€§: {stability_metrics['utilization_stability']:.2f}")
    print(f"    å¹³å‡æ¯æ—¥è¡çª: {stability_metrics['conflict_frequency']:.1f} å€‹")
    print(f"    å¹³å‡æ¯æ—¥åŠ ç­: {stability_metrics['overtime_frequency']:.1f} å°æ™‚")
    
    # ç³»çµ±å¥åº·åº¦è©•åˆ†
    health_score = 100
    
    if stability_metrics['avg_success_rate'] < 90:
        health_score -= 20
    elif stability_metrics['avg_success_rate'] < 95:
        health_score -= 10
    
    if stability_metrics['success_rate_stability'] > 10:
        health_score -= 15
    
    if stability_metrics['conflict_frequency'] > 2:
        health_score -= 15
    
    if stability_metrics['overtime_frequency'] > 5:
        health_score -= 10
    
    print(f"\n  ç³»çµ±å¥åº·åº¦è©•åˆ†: {health_score}/100")
    
    if health_score >= 90:
        print(f"  âœ… ç³»çµ±é‹ä½œå„ªè‰¯")
    elif health_score >= 75:
        print(f"  âš ï¸ ç³»çµ±é‹ä½œè‰¯å¥½ï¼Œæœ‰æ”¹å–„ç©ºé–“")
    else:
        print(f"  âŒ ç³»çµ±é‹ä½œéœ€è¦é‡å¤§æ”¹å–„")
    
    # Step 6: ç“¶é ¸è­˜åˆ¥
    print(f"\nğŸ” Step 6: ç“¶é ¸è­˜åˆ¥...")
    
    bottlenecks = []
    
    if stability_metrics['avg_success_rate'] < 90:
        bottlenecks.append("ä»»å‹™åˆ†é…æˆåŠŸç‡åä½")
    
    if stability_metrics['success_rate_stability'] > 10:
        bottlenecks.append("åˆ†é…æˆåŠŸç‡ä¸ç©©å®š")
    
    if stability_metrics['avg_utilization'] > 85:
        bottlenecks.append("å·¥ä½œç«™åˆ©ç”¨ç‡éé«˜")
    elif stability_metrics['avg_utilization'] < 60:
        bottlenecks.append("å·¥ä½œç«™åˆ©ç”¨ç‡åä½")
    
    if stability_metrics['conflict_frequency'] > 1:
        bottlenecks.append("å·¥ä½œç«™è¡çªé »ç¹")
    
    if stability_metrics['overtime_frequency'] > 3:
        bottlenecks.append("åŠ ç­éœ€æ±‚éé«˜")
    
    if receiving_backlog:
        bottlenecks.append("é€²è²¨ä»»å‹™ç©å£“")
    
    if bottlenecks:
        print(f"  ç™¼ç¾ç“¶é ¸:")
        for i, bottleneck in enumerate(bottlenecks, 1):
            print(f"    {i}. {bottleneck}")
    else:
        print(f"  âœ… æœªç™¼ç¾æ˜é¡¯ç“¶é ¸")
    
    # Step 7: æ”¹å–„å»ºè­°
    print(f"\nğŸ’¡ Step 7: æ”¹å–„å»ºè­°...")
    
    recommendations = []
    
    if "ä»»å‹™åˆ†é…æˆåŠŸç‡åä½" in bottlenecks:
        recommendations.append("æª¢è¨ä»»å‹™åˆ†é…æ¼”ç®—æ³•ï¼Œè€ƒæ…®å¢åŠ å·¥ä½œç«™æ•¸é‡")
    
    if "åˆ†é…æˆåŠŸç‡ä¸ç©©å®š" in bottlenecks:
        recommendations.append("åˆ†æé€ æˆä¸ç©©å®šçš„æ—¥æœŸæ¨¡å¼ï¼Œèª¿æ•´æ’ç­ç­–ç•¥")
    
    if "å·¥ä½œç«™åˆ©ç”¨ç‡éé«˜" in bottlenecks:
        recommendations.append("è€ƒæ…®å¢åŠ å·¥ä½œç«™æˆ–èª¿æ•´ä½œæ¥­æ™‚é–“")
    
    if "å·¥ä½œç«™è¡çªé »ç¹" in bottlenecks:
        recommendations.append("å„ªåŒ–æ³¢æ¬¡æ™‚é–“è¦åŠƒï¼Œå¢åŠ å·¥ä½œç«™é–“ç·©è¡æ™‚é–“")
    
    if "åŠ ç­éœ€æ±‚éé«˜" in bottlenecks:
        recommendations.append("é‡æ–°è©•ä¼°æ¨™æº–ä½œæ¥­æ™‚é–“ï¼Œè€ƒæ…®å¢åŠ å¸¸è¦ç­æ¬¡äººåŠ›")
    
    if "é€²è²¨ä»»å‹™ç©å£“" in bottlenecks:
        recommendations.append("å»ºç«‹é€²è²¨ä»»å‹™å„ªå…ˆè™•ç†æ©Ÿåˆ¶ï¼Œé¿å…é€¾æœŸç´¯ç©")
    
    if not recommendations:
        recommendations.append("ç³»çµ±é‹ä½œè‰¯å¥½ï¼Œå»ºè­°æŒçºŒç›£æ§å’Œå¾®èª¿")
    
    for i, recommendation in enumerate(recommendations, 1):
        print(f"    {i}. {recommendation}")
    
    # Step 8: è¼¸å‡ºç¶œåˆå ±å‘Š
    print(f"\nğŸ“ Step 8: è¼¸å‡ºç¶œåˆå ±å‘Š...")
    
    # è¶¨å‹¢è³‡æ–™
    if trend_data:
        trend_df = pd.DataFrame(trend_data)
        output_file = os.path.join(os.path.dirname(__file__), '..', 'output', 
                                 f'multi_day_trends_{start_date}_to_{end_date}.csv')
        trend_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"  è¶¨å‹¢åˆ†æ: {output_file}")
    
    # ç©©å®šæ€§å ±å‘Š
    stability_report = {
        'period': f"{start_date} to {end_date}",
        'total_days': total_days,
        'working_days': len([r for r in daily_results.values() if r is not None]),
        **stability_metrics,
        'health_score': health_score,
        'bottlenecks': '; '.join(bottlenecks),
        'recommendations': '; '.join(recommendations)
    }
    
    stability_df = pd.DataFrame([stability_report])
    output_file = os.path.join(os.path.dirname(__file__), '..', 'output', 
                             f'stability_report_{start_date}_to_{end_date}.csv')
    stability_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"  ç©©å®šæ€§å ±å‘Š: {output_file}")
    
    # ç´¯ç©æŒ‡æ¨™å ±å‘Š
    cumulative_report = {
        'period': f"{start_date} to {end_date}",
        **cumulative_metrics,
        'avg_utilization': np.mean(cumulative_metrics['avg_utilization']) if cumulative_metrics['avg_utilization'] else 0,
        'avg_success_rate': np.mean(cumulative_metrics['avg_success_rate']) if cumulative_metrics['avg_success_rate'] else 0
    }
    
    # ç§»é™¤åˆ—è¡¨æ¬„ä½ä»¥ä¾¿å­˜æˆCSV
    cumulative_report_clean = {k: v for k, v in cumulative_report.items() 
                             if not isinstance(v, list)}
    
    cumulative_df = pd.DataFrame([cumulative_report_clean])
    output_file = os.path.join(os.path.dirname(__file__), '..', 'output', 
                             f'cumulative_metrics_{start_date}_to_{end_date}.csv')
    cumulative_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"  ç´¯ç©æŒ‡æ¨™: {output_file}")
    
    # Step 9: ç¸½çµ
    print(f"\nğŸ“‹ Step 5 é©—è­‰ç¸½çµ:")
    print(f"  é©—è­‰æœŸé–“: {start_date} è‡³ {end_date} ({total_days} å¤©)")
    print(f"  æˆåŠŸè™•ç†: {len([r for r in daily_results.values() if r is not None])} å¤©")
    print(f"  ç¸½è™•ç†è¨‚å–®: {cumulative_metrics['total_orders_processed']:,} ç­†")
    print(f"  å¹³å‡åˆ†é…æˆåŠŸç‡: {stability_metrics['avg_success_rate']:.1f}%")
    print(f"  å¹³å‡å·¥ä½œç«™åˆ©ç”¨ç‡: {stability_metrics['avg_utilization']:.1f}%")
    print(f"  ç³»çµ±å¥åº·åº¦: {health_score}/100")
    print(f"  ä¸»è¦ç“¶é ¸: {bottlenecks[0] if bottlenecks else 'ç„¡'}")
    
    return {
        'period': f"{start_date} to {end_date}",
        'daily_results': daily_results,
        'trend_data': trend_data,
        'stability_metrics': stability_metrics,
        'health_score': health_score,
        'bottlenecks': bottlenecks,
        'recommendations': recommendations,
        'cumulative_metrics': cumulative_metrics
    }

def run_single_day_validation(date_str):
    """åŸ·è¡Œå–®æ—¥é©—è­‰ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
    try:
        # é€™è£¡æ‡‰è©²èª¿ç”¨ step4 çš„é‚è¼¯
        # ç‚ºäº†é¿å…å¾ªç’°å°å…¥ï¼Œé€™è£¡ä½¿ç”¨ç°¡åŒ–çš„æ¨¡æ“¬çµæœ
        
        # æ¨¡æ“¬å–®æ—¥è™•ç†çµæœ
        base_orders = np.random.randint(50, 200)
        success_rate = np.random.uniform(85, 98)
        utilization = np.random.uniform(60, 90)
        conflicts = np.random.randint(0, 3)
        overtime = np.random.uniform(0, 8)
        
        return {
            'daily_summary': {
                'total_shipping_orders': base_orders,
                'total_assigned_tasks': int(base_orders * success_rate / 100),
                'total_unassigned_tasks': int(base_orders * (100 - success_rate) / 100),
                'assignment_success_rate': success_rate,
                'peak_station_utilization': utilization,
                'station_conflicts': conflicts,
                'estimated_overtime_hours': overtime,
                'total_receiving_tasks': np.random.randint(0, 20)
            },
            'overtime_analysis': {
                'overtime_by_type': {
                    'receiving': np.random.randint(0, 5)
                }
            }
        }
    
    except Exception:
        return None

if __name__ == "__main__":
    try:
        # å¯ä»¥ä¿®æ”¹é€™äº›åƒæ•¸ä¾†æ¸¬è©¦ä¸åŒçš„æœŸé–“
        start_date = "2024-06-10"
        end_date = "2024-06-16"
        
        result = validate_multi_day_operations(start_date, end_date)
        print(f"\nğŸ¯ å¤šå¤©é€£çºŒé‹ä½œé©—è­‰å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()